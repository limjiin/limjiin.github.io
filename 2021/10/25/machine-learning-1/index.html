<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"limjiin.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="드디어 머신러닝까지 왔다! 수학적 개념이 많이 사용되어서 공부가 필요하지만, 이번에도 차근차근 공부해보쟈! 아자자!">
<meta property="og:type" content="article">
<meta property="og:title" content="머신러닝  1편">
<meta property="og:url" content="https://limjiin.github.io/2021/10/25/machine-learning-1/index.html">
<meta property="og:site_name" content="야무진의 기술 블로그">
<meta property="og:description" content="드디어 머신러닝까지 왔다! 수학적 개념이 많이 사용되어서 공부가 필요하지만, 이번에도 차근차근 공부해보쟈! 아자자!">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2021-10-25T09:18:44.055Z">
<meta property="article:modified_time" content="2021-10-26T06:25:52.240Z">
<meta property="article:author" content="limjiin">
<meta property="article:tag" content="machine">
<meta property="article:tag" content="learning">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://limjiin.github.io/2021/10/25/machine-learning-1/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>머신러닝  1편 | 야무진의 기술 블로그</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">야무진의 기술 블로그</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">데이터 마케터 짜그리이지만, 계속 해보겠습니다.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://limjiin.github.io/2021/10/25/machine-learning-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="limjiin">
      <meta itemprop="description" content="All stories about git, sql, python">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="야무진의 기술 블로그">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          머신러닝  1편
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-10-25 18:18:44" itemprop="dateCreated datePublished" datetime="2021-10-25T18:18:44+09:00">2021-10-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-10-26 15:25:52" itemprop="dateModified" datetime="2021-10-26T15:25:52+09:00">2021-10-26</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/machine-learning/" itemprop="url" rel="index"><span itemprop="name">machine-learning</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/2021/10/25/machine-learning-1/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2021/10/25/machine-learning-1/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>드디어 머신러닝까지 왔다! 수학적 개념이 많이 사용되어서 공부가 필요하지만, 이번에도 차근차근 공부해보쟈! 아자자!</p>
<span id="more"></span>

<h3 id="Part-01-머신러닝의-개념과-종류"><a href="#Part-01-머신러닝의-개념과-종류" class="headerlink" title="Part.01 머신러닝의 개념과 종류"></a>Part.01 머신러닝의 개념과 종류</h3><ol>
<li>머신러닝의 개념</li>
</ol>
<ul>
<li><p>무엇(x)으로 무엇(y)을 예측하고 싶다.</p>
</li>
<li><p>기계 학습 또는 머신 러닝은 인공 지능의 한 분야로, 컴퓨터가 학습할 수 있도록 하는 알고리즘과 기술을 개발하는 분야</p>
<blockquote>
<p>주어진 데이터를 통해 입력변수와 출력변수 간의 관계를 만드는 함수를 만드는 것<br>주어진 데이터 속에서 데이터의 특징을 찾아내는 함수를 만드는 것</p>
</blockquote>
</li>
<li><p>머신 러닝으로 할 수 있는 것들</p>
<blockquote>
<p>X : 고객들의 개인 정보 및 금융 관련 정보, Y : 대출 연체 여부<br>X : 상품 구매 고객 특성 정보 -&gt; 군집화를 통한 고객 특성에 따른 세그멘테이션<br>X : SNS 데이터 및 뉴스 데이터 -&gt; 소셜 및 사회 이슈 파악</p>
</blockquote>
</li>
<li><p>함수 f(x) = Y</p>
<blockquote>
<p>f를 구하기 위해 입력 변수와 출력 변수가 필요함<br>p개의 입력 변수가 있고, 출력 변수 Y가 있을 때, X라 하면 입력 변수와 출력 변수가 나타내는 식</p>
</blockquote>
</li>
</ul>
<ol start="2">
<li>지도 학습과 비지도 학습</li>
</ol>
<ul>
<li><p>지도 학습</p>
<blockquote>
<p>Y = f(x) 에 대하여 입력 변수(x)와 출력 변수(y)의 관계에 대해 모델링 하는 것(Y에 대해 예측 또는 분류)<br>회귀 : 입력 변수 X에 대해 연속형 출력 변수 Y를 예측<br>분류 : 입력 변수 X에 대해 이산형 출력 변수 Y를 예측<br>예 : 주식가격 예측, 공정 불량 여부 탐지</p>
</blockquote>
</li>
<li><p>비지도 학습</p>
<blockquote>
<p>출력 변수가 존재하지 않고, 입력 변수 간의 관계에 대해 모델링<br>군집 분석 : 유사한 데이터끼리 그룹화<br>PCA : 독립변수들의 차원을 축소화<br>예 : 고객 segmentation</p>
</blockquote>
</li>
<li><p>강화학습</p>
<blockquote>
<p>수 많은 시뮬레이션을 통해 현재의 선택이 먼 미래에 보상이 최대가 되도록 학습<br>Agent가 action을 취하고 환경에서 보상을 받고 이 보상이 최대가 되도록 최적의 action을 취하는 것<br>예 : 알파고</p>
</blockquote>
</li>
</ul>
<ol start="3">
<li>머신러닝의 종류</li>
</ol>
<ul>
<li><p>선형 회귀분석</p>
<blockquote>
<p>독립 변수와 종속 변수가 선형적인 관계가 있다는 가정 하에 분석<br>직선을 통해 종속 변수를 예측하기 때문에 독립 변수의 중요도와 영향력을 파악하기 쉬움<br>단 비선형 관계는 파악하기 어려움</p>
</blockquote>
</li>
<li><p>의사결정나무(Decision Tree)</p>
<blockquote>
<p>독립 변수의 조건에 따라 종속 변수를 분리<br>이해하기 쉬우나 overfitting이 잘 일어남</p>
</blockquote>
</li>
<li><p>KNN(K-Nearest Neighbor)</p>
<blockquote>
<p>새로 들어온 데이터의 주변 K개의 데이터의 class로 분류하는 기법</p>
</blockquote>
</li>
<li><p>Neural Network</p>
<blockquote>
<p>입력, 은닉, 출력층으로 구성된 모형으로서 각 층을 연결하는 노드의 가중치를 업데이트 하면서 학습</p>
</blockquote>
</li>
<li><p>SVM(support vector machine)</p>
<blockquote>
<p>class 간의 거리가 최대가 되도록 decision boundary를 만드는 방법</p>
</blockquote>
</li>
<li><p>Ensemble Learning</p>
<blockquote>
<p>여러 개의 모델(classifier or base learner)을 결합하여 사용하는 모델</p>
</blockquote>
</li>
<li><p>K-means clustering</p>
<blockquote>
<p>Label 없이 데이터의 군집으로 k개로 생성</p>
</blockquote>
</li>
</ul>
<ol start="4">
<li>딥러닝의 주요 모델</li>
</ol>
<ul>
<li><p>참고 : Neural Network</p>
<blockquote>
<p>입력, 은닉, 출력층으로 구성된 모형으로서 각 층을 연결하는 노드의 가중치를 업데이트 하면서 학습<br>Overfitting이 심하게 일어나고 학습기간이 매우 오래걸림</p>
</blockquote>
</li>
<li><p>Deep Learning</p>
<blockquote>
<p>다층의 layer를 통해 복잡한 데이터의 학습이 가능토록 함<br>알고리즘 및 GPU의 발전이 딥러닝의 부흥을 이끔<br>다양한 형태로 발전(CNN, RNN, AutoEncoder 등)<br>다양한 분야로 발전<br>네트워크 구조의 발전(ResNET, DenseNET 등)<br>네트워크 초기화 기법<br>다양한 activation function<br>Generalization, overfitting<br>Semi-supervised learning, Unsupervised learning</p>
</blockquote>
</li>
<li><p>GAN(Generative Adversarial Network)</p>
<blockquote>
<p>Data를 만들어내는 Generator와 만들어진 data를 평가하는 Discriminator가 서로 대립적으로 학습해가며 성능을 점차 개선해 나가자는 개념<br>-Discriminator를 학습시킬 때는 D(x)가 1이 되고 D(G(z))가 0이 되도록 학습시킴(진짜 데이터를 진짜로 판별하고, 가짜데이터를 가짜로 판별할 수 있도록)<br>-Generator를 학습시킬 때는 D(G(z))가 1이 되도록 학습시킴(가짜데이터를 discriminator가 구분 못하도록 학습, discriminator를 헷갈리게 하도록)</p>
</blockquote>
</li>
<li><p>강화 학습(Reinforcement Learning)</p>
<ul>
<li>Q-learning : 현재 상태에서 먼 미래까지 가장 큰 보상을 얻을 수 있는 행동을 학습</li>
<li>Q-learning + Deep Learning : DQN(Deep Reinforcement Learning)</li>
</ul>
<ul>
<li>더 효율적으로 빠르게 학습 할 수 있는 강화학습 모델</li>
<li>Action이 continuous한 경우</li>
<li>Reward가 매우 희박(sparse)한 경우</li>
<li>Multi agent 강화학습 모델</li>
</ul>
</li>
<li><p>마무리 : 머신러닝 -&gt; 딥러닝 -&gt; 이미지, 텍스트, Generalization -&gt; GAN, Reinforcement Learning</p>
</li>
</ul>
<ol start="5">
<li>모형의 적합성 평가 및 실험 설계</li>
</ol>
<ul>
<li><p>모형의 적합성을 평가하는 방법</p>
<blockquote>
<p>모형의 복잡도에 따른 학습 집합의 MSE(회색)와 검증 집합의 MSE(빨간색)의 변화는 아래 그림과 같음<br>학습 집합의 MSE는 복잡한 모형일수록 감소하지만, 학습 데이터가 아닌 또 다른 데이터(검증 데이터)의 MSE는 일정 시점 이후 증가<br>증가하는 원인은 왼쪽 그림과 같이 모형이 학습 집합에 과적합되기 때문</p>
</blockquote>
</li>
<li><p>데이터 분할</p>
<blockquote>
<p>과적합을 방지하기 위해 전체 데이터를 학습 데이터, 검증 데이터, 테스트 데이터로 나누며 보통 비율은 5:3:2로 정함<br>데이터 분할 &gt; 모형 학습 &gt; 모형 선택 &gt; 최종 성능 지표 도출</p>
</blockquote>
</li>
<li><p>K-fold 교차 검증(cross validation)</p>
<blockquote>
<p>모형의 적합성을 보다 객관적으로 평가하기 위한 방법<br>데이터를 K(주로 5 또는 10)개 부분으로 나눈 뒤, 그 중 하나를 검증 집합, 나머지를 학습 집합으로 분류<br>위 과정을 K번 반복하고 K개의 성능 지표를 평균하여 모형의 적합성 평가</p>
</blockquote>
</li>
<li><p>LOOCV(Leave-one-out cross validation)</p>
<blockquote>
<p>데이터의 수가 적을 때 사용하는 교차검증 방법<br>총 n개의 모델을 만드는데, 각 모델은 하나의 샘플만 제외하면서 모델을 만들고 제외한 샘플로 성능 지표를 계산함. 도출된 n개의 성능 지표를 평균 내어 최종 성능 지표를 도출</p>
</blockquote>
</li>
<li><p>마무리 </p>
<blockquote>
<p>데이터가 적은 경우 : LOOCV<br>데이터가 애매하게 많은 경우 : K-Fold 교차 검증<br>그 외 : 데이터 분할 : 데이터 분할</p>
</blockquote>
</li>
</ul>
<ol start="6">
<li>모형의 적합성 평가 및 실험(데이터분석과정)</li>
</ol>
<ul>
<li><p>데이터 분석 과정</p>
<blockquote>
<p>raw 데이터 -&gt; 전처리 된 데이터 -&gt; 실험설계 -&gt; Model</p>
</blockquote>
</li>
<li><p>전처리 : Raw 데이터를 모델링 할 수 있도록 데이터를 병합 및 파생 변수 생성</p>
</li>
<li><p>실험 설계</p>
<blockquote>
<p>test 데이터는 실제로 우리가 모델을 적용 한다는 가정 하에 test 데이터 없이 실험 설계<br>Train, Validation 데이터에 test 정보는 없어야 함</p>
</blockquote>
</li>
</ul>
<ol start="7">
<li>과적합(Overfitting)이란</li>
</ol>
<ul>
<li><p>과적합이란</p>
<blockquote>
<p>복합한 모형일수록, 데이터가 적을수록 과적합이 일어나기 쉬움<br>아래 그림은 회귀분석에서 고차향을 넣었을 때 만들어지는 직선<br>과적합은 data science 뿐만 아니라 AI 전반적으로 매우 큰 이슈</p>
</blockquote>
</li>
<li><p>분산과 편파성의 트레이드 오프</p>
<blockquote>
<p>모형 f^(x)로 모집단의 전체 데이터를 예측할 때 발생하는 총 error를 계산하면 reducible error와 irreducible error로 표현되며, reducible error는 다시 분산과 편파성으로 구성<br>분산 : 전체 데이터 집합 중 다른 학습 데이터를 이용했을 때, f^이 변하는 정도<br>편파성 : 학습 알고리즘에서 잘못된 가정을 했을 때 발생하는 오차<br>복잡한 모형 f^(x)을 사용하여 편파성을 줄이면, 반대로 분산이 커짐<br>예측값과 실제값은 분산과 예측할 수 있는 정도와 어쩔 수 없이 예측할 수 있는 오차 범위로 이루어져 있다.<br>적절한 모형의 선택과 실험 설계를 통한 과적합 방지(표본은 모집단을 완벽하게 대표하지 않으니까)</p>
</blockquote>
</li>
</ul>
<h3 id="Part-02-회귀분석"><a href="#Part-02-회귀분석" class="headerlink" title="Part. 02 회귀분석"></a>Part. 02 회귀분석</h3><ol>
<li>회귀분석을 위한 통계 : 수학적 개념 이해 - 통계학</li>
</ol>
<ul>
<li><p>모집단(population) &lt; (추정 추론) - (표본 추출) &gt; 표본(sample)</p>
<blockquote>
<p>모집단 : 연구의 대상이 되는 모든 개체들을 모은 집합<br>일반적으로 시간적, 공간적 제약으로 인해 모집단 전체를 대상으로 한 분석은 불가능<br>표본 : 모집단의 일부분의 관측값들</p>
</blockquote>
</li>
<li><p>모집단 : 모집단의 요약값 &lt; (추정 추론) - 표본 : 통계량</p>
<blockquote>
<p>모수(Parameter) : 수치로 표현되는 모집단의 특성<br>통계량(Statistic) : 표본의 관측값들에 의해 결정되는 양</p>
</blockquote>
</li>
<li><p>자료의 종류</p>
<ul>
<li>수치형(양적 자료)</li>
</ul>
<ul>
<li>연속형(몸무게, 키) : 값 사이에 새로운 값을 넣을 수 있음</li>
<li>이산형(전화 통화 수) : 분절</li>
</ul>
<ul>
<li>범주형(질적 자료)</li>
</ul>
<ul>
<li>순위형(학점)</li>
<li>명목형(성별) : 순위 없음</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th>반응 변수</th>
<th>설명변수(범주형)</th>
<th>설명변수(연속형)</th>
</tr>
</thead>
<tbody><tr>
<td>범주형(이산형)</td>
<td>범주형 자료 분석</td>
<td>로지스틱 회귀분석</td>
</tr>
<tr>
<td>연속형</td>
<td>분산분석</td>
<td>회귀분석</td>
</tr>
</tbody></table>
<ul>
<li>자료의 요약 - 그림, 표<blockquote>
<p>범주형 자료 : 도수 분포표, 막대/원형 그래프<br>연속형 자료 : Box plot, 히스토그램(Histogram)</p>
</blockquote>
</li>
</ul>
<ol start="2">
<li>수학적 개념 이해 : 기술통계량, 추정량</li>
</ol>
<ul>
<li><p>자료의 요약 : 수치</p>
</li>
<li><p>모집단 개체의 수 : N</p>
</li>
<li><p>중심 경향값 (대표값)</p>
<blockquote>
<p>평균(값의 변화에 따라 영향을 받음)<br>중앙값 : 크기 순으로 정렬시켜 중앙에 위치한 값(값의 변화에 영향이 적음)<br>최빈값 : 가장 자주 나오는 값</p>
</blockquote>
</li>
<li><p>산포도(퍼진 정도)</p>
<blockquote>
<p>분산<br>사분위수 범위 : 전체 관측값을 크기순으로 정렬했을 떄 중앙에 위치한 50%의 관측치가 가지는 범위</p>
</blockquote>
</li>
<li><p>정규 분포</p>
<blockquote>
<p>자연과학 현상을 설명할 때 가장 널리 쓰이는 분포<br>위치는 평균에 의해, 모양은 분산에 의해 결정</p>
</blockquote>
</li>
<li><p>분포도</p>
<blockquote>
<p>왜도 : 분포의 비대칭 정도, Left-skewed를 Negative skewed로 표현하기도 함</p>
</blockquote>
</li>
<li><p>첨도(Kurtosis)</p>
<blockquote>
<p>분포의 꼬리 부분의 비중에 대한 측도<br>Ks = 0 : 뾰족한 정도가 정규 분포와 동일</p>
</blockquote>
</li>
<li><p>통계학이란 ? 리뷰</p>
<blockquote>
<p>모수<br>통계량<br>추정량</p>
</blockquote>
</li>
<li><p>통계량, 추정량</p>
<ul>
<li>추정량의 종류 (표본 관측치의 개수 : n)</li>
</ul>
<ul>
<li>표본 평균</li>
<li>표본 분산</li>
</ul>
</li>
</ul>
<ol start="2">
<li>수학적 개념 이해 : 확률</li>
</ol>
<ul>
<li><p>확률</p>
<ul>
<li>확률 실험(Random experiment) : 다음과 같은 속성을 지닌 관찰이나 인위적인 실험</li>
</ul>
<ul>
<li>결과를 미리 알 수 없다</li>
<li>실험에서 일어날 수 있는 모든 결과는 사전에 알려져 있다</li>
<li>이론적으로는 실험을 반복할 수 있다</li>
</ul>
<ul>
<li>표본공간(Sample space): 모든 결과들의 모임</li>
<li>근원사건(Sample outcome) : 표본 공간의 원소</li>
<li>사건(Event) : 표본 공간의 부분집합. 근원사건의 집합</li>
</ul>
<ul>
<li>배반 사건(Mutually exclusive events) : 서로 교집합이 공집합인 사건</li>
</ul>
<ul>
<li>예 : 주사위, 동전 던지기</li>
</ul>
</li>
<li><p>확률 값</p>
<ul>
<li>어떠한 사건이 일어날 가능성의 정도</li>
<li>근원사건이 일어날 가능성이 동일할 때의 계산</li>
<li>확률의 공리</li>
</ul>
<ul>
<li>어떠한 사건들이 서로 배반사건일 때, 이 사건들의 합 사건의 확률은 각각의 사건이 일어날 확률의 합과 같다</li>
</ul>
<ul>
<li>조건부 확률</li>
</ul>
<ul>
<li>사건 B에 대한 정보가 주어졌을 때, 사건 A의 교정된 확률</li>
<li>B가 주어졌을 때 사건 A의 조건부 확률</li>
</ul>
</li>
<li><p>독립</p>
<blockquote>
<p>사건 A와 B가 서로에게 아무런 영향을 미치지 않을 때 </p>
</blockquote>
</li>
<li><p>확률 변수, 확률 분포</p>
<blockquote>
<p>확률 변수 : 각각의 근원 사건들에 실수 값을 대응시키는 함수<br>확률 분포 : 확률 변수에서 확률값으로의 함수. 주로 f(x)로 표기<br>확률 변수의 기대값 : 확률 변수의 중심 경향 값. 흔히 평균<br>확률 변수의 분산<br>공분산</p>
</blockquote>
<ul>
<li>두 개의 확률 변수 X, Y가 상호 어떤 관계를 가지며 변화하는 가를 나타내는 척도</li>
</ul>
</li>
<li><p>X, Y가 독립이면 Cov(X, Y) = 0</p>
<ul>
<li>상관계수</li>
</ul>
<ul>
<li>공분산은 X, Y단위의 크기에 영향을 받음</li>
<li>상관계수는 공분산을 단위화한 값</li>
</ul>
</li>
<li><p>이산형 확률분포</p>
<blockquote>
<p>베르누이 시행 : 실험의 결과 범주가 2가지인 경우(성공/실패)<br>이항분포 : 성공확률이 p인 베르누이 시행을 독립적으로 n번 시행했을 때 성공한 횟수의 분포</p>
</blockquote>
</li>
<li><p>다항 분포</p>
<blockquote>
<p>다항 시행 : 1회의 시행결과로 나올 수 있는 범주가 3개 이상이 되는 확률 시험<br>K개 범주의 다항 시행을 n번 반복했을 때, 각 범주가 나타나는 횟수의 분포</p>
</blockquote>
</li>
<li><p>포아송분포</p>
<ul>
<li>주어진 단위 구간 내에 평균적으로 발생하는 사건의 횟수가 정해져 있을 때, 동일 단위에서의 발생 횟수</li>
</ul>
<ul>
<li>사건의 평균 발생횟수는 단위 구간에 비혜</li>
<li>두 개 이상의 사건이 동시에 발생할 확률은 0에 가깝다</li>
<li>어떤 단위구간의 사건 발생은 다른 단위 구간의 발생으로부터 독립적</li>
<li>100페이지 안에 있는 오타의수, 1시간 동안 걸려온 전화의 수</li>
</ul>
</li>
<li><p>지수분포 </p>
</li>
<li><p>정규분포</p>
</li>
<li><p>표준정규분포 : 평균이 0이고 분산이 1인 정규분포</p>
</li>
</ul>
<ol start="3">
<li>수학적 개념 이해 : 추정, 추론</li>
</ol>
<ul>
<li><p>통계적 추론</p>
<ul>
<li>점 추정(point estimation) : 추정량을 통해 모수를 추정</li>
<li>구간 추정(interval estimation)</li>
</ul>
<ul>
<li>일정 신뢰수준 하에서 모수를 포함할 것으로 예상되는 구간을 제시</li>
<li>신뢰 수준(1-a)과 구간의 길이는 반비례</li>
</ul>
</li>
<li><p>통계적 검정</p>
<ul>
<li>대립가설 : 입증하여 주장하고자 하는 가설</li>
<li>귀무가설</li>
</ul>
<ul>
<li>대립가설의 반대가설</li>
<li>귀무가설이 아니라는 충분한 증거를 데이터로부터 보임으로써 대립가설을 입증</li>
<li>귀무가설 하에서 통계량의 분포를 아는 것이 검정의 핵심</li>
</ul>
</li>
<li><p>오류의 종류</p>
<blockquote>
<p>1종 오류 : 귀무가설이 맞을 때, 귀무가설을 기각하는 오류<br>2종 오류 : 귀무가설이 틀렸을 때 귀무가설을 기각하지 않는 오류</p>
</blockquote>
</li>
<li><p>검정통계량, 기각역</p>
<ul>
<li>검정통계량</li>
</ul>
<ul>
<li>표본에서 구해낼 수 있는 함수. 이 값을 기준으로 귀무가설 기각여부를 결정</li>
</ul>
<ul>
<li>기각역</li>
</ul>
<ul>
<li>검정통계량이 취하는 구간 중 귀무가설을 기각하는 구간</li>
</ul>
<ul>
<li>단측 검정</li>
<li>양측 검정</li>
</ul>
</li>
<li><p>유의 확률(P-value)</p>
<blockquote>
<p>주어진 검정통계량의 값을 기준으로 해당 값보다 대립 가설을 더 선호하는 검정통계량 값이 나올 확률<br>이 값이 유의수준보다 낮으면 귀무가설을 기각<br>참고 : 기각역</p>
</blockquote>
</li>
<li><p>검정통계량과 관련된 분포</p>
<blockquote>
<p>Z 통계량<br>t 분포 : 자유도가 커질수록 정규분포에 근사<br>카이제곱 분포 : 확률변수의 제곱합으로 이루어진 통계량<br>F 분포</p>
</blockquote>
<ul>
<li>두 확률변수가 자유도이고, 서로 독립인 카이제곱 분포를 따를 때</li>
<li>확률변수의 제곱합을 관측치로 나눈 것의 비율로 이루어진 통계량</li>
</ul>
</li>
</ul>
<ol start="4">
<li>수학적 개념 이해 : 미분의 개념</li>
</ol>
<ul>
<li><p>평균 변화율</p>
</li>
<li><p>순간 변화율</p>
<blockquote>
<p>평균 변화율의 극한 값<br>b점이 a점으로 한없이 가까워질 때, a점에서의 순간 변화율<br>a점에서의 접선의 기울기</p>
</blockquote>
</li>
<li><p>미분의 개념</p>
<blockquote>
<p>다항함수의 미분 및 미분 기본 공식<br>곱의 미분<br>합성함수 미분<br>지수함수 미분<br>로그함수 미분</p>
</blockquote>
</li>
<li><p>미분의 활용</p>
<blockquote>
<p>극대값, 극소값 : 미분값은 접선의 기울도함수를 통하여 미분가능한 함수의 극대값, 극소값을 구할 수 있음</p>
</blockquote>
</li>
<li><p>Likelihood</p>
<ul>
<li>Likelihood function(가능도함수/우도함수)</li>
<li>확률분포함수 : 모수를 알 때, 확률변수의 실현값을 예측하고자 함</li>
<li>종류</li>
</ul>
<ul>
<li>확률밀도함수 : 연속형 확률변수의 확률 분포함수</li>
<li>확률질량함수 : 이산형 확률변수의 확률 분포함수</li>
<li>누적분포함수 : 누적 확률 분포함수</li>
</ul>
</li>
</ul>
<blockquote>
<p>가능도함수 : 확률 변수의 실현값을 알 때, 데이터가 있을 때 모수를 추정하고자 함<br>미분의 활용 : MLE<br>MLE(Maximum Likelihood Estimator) : Likelihood를 최대로 만드는 모수의 값</p>
</blockquote>
<ol start="5">
<li>수학적 개념 이해 : Matrix 정의 및 성질</li>
</ol>
<ul>
<li><p>Matrix 표기법</p>
<blockquote>
<p>Matrix<br>Vector : 행 또는 열의 수가 1인 경우, 전자는 row vector 후자는 column vector<br>Transpose and symmetric</p>
</blockquote>
</li>
<li><p>Matrix</p>
<blockquote>
<p>Scalar : 1 by 1 matrix<br>Identity matrix<br>Diagonal matrix<br>Equality : 모든 i, j에 대해<br>합, 차의 성질<br>곱 : 상수배, 행렬곱<br>내적 : Row vector 와 Column vector의 곱<br>행렬 곱의성질<br>Trace<br>행렬식 (determinant) |A| 구하기<br>2 by 2 matrix<br>역행렬(Inverse)<br>Idempotent : AA = A</p>
</blockquote>
</li>
</ul>
<ol start="6">
<li>Matrix 미분</li>
</ol>
<ul>
<li><p>미분 표기법의 종류</p>
<blockquote>
<p>Matrix 미분을 헷갈리게 하는 이유 : 서로 다른 표기법이 존재<br>대부분 책에서 명시하지 않고 사용하기에 두 표기법의 개념을 모두 알아두는 것이 좋은</p>
</blockquote>
</li>
<li><p>Numerator layout</p>
<blockquote>
<p>미분 당하는 변수 혹은 함수를 기준으로 결과의 형태를 표기</p>
</blockquote>
</li>
<li><p>Denumerator layout</p>
<blockquote>
<p>미분을 하는 변수 혹은 함수를 기준으로 결과의 형태를 표기</p>
</blockquote>
</li>
<li><p>핵심 : 의도한 미분을 수행했을 때 결과값의 차원</p>
</li>
<li><p>Scalar를 vector로 미분</p>
</li>
<li><p>Vector를 vector로 미분</p>
</li>
<li><p>주요 미분 결과 간편 활용 방법</p>
<ul>
<li>내적 형태</li>
</ul>
<ul>
<li>미분하면 a 꼴이 나올 것. 스칼라 - 벡터의 미분 &gt; 분모 차원의 반대. 1 X p 만들어주기</li>
</ul>
<ul>
<li>Matrix - vector 곱 형태(Linear from)</li>
</ul>
<ul>
<li>미분하면 a 꼴이 나올 것. 벡터 - 벡터의 미분 &gt; 분자 차원 유지. A의 행차원 같이 만들어주기</li>
</ul>
<ul>
<li>제곱 형태 (Quadratic form)</li>
</ul>
<ul>
<li>미분하면 (A + At)x 꼴이 나올 것. 스칼라 - 벡터의 미분 &gt; 분모 차원의 반대. 1 X p 만들어주기</li>
</ul>
</li>
<li><p>회귀분석에 적용</p>
</li>
</ul>
<ol start="7">
<li>회귀분석이란</li>
</ol>
<ul>
<li><p>지도 학습(supervised learning)</p>
<blockquote>
<p>Y = f(x) 에 대해 입력 변수(x)와 출력 변수(y)의 관계에 대하여 모델링하는 것(Y에 대해 예측 또는 분류하는 문제)<br>회귀(regression) : 입력 변수 x에 대해 연속형 출력 변수 y를 예측<br>분류(classification) : 입력 변수 x에 대해서 이산형 출력 변수 y(class)를 예측 </p>
</blockquote>
</li>
<li><p>입력 변수인 x의 정보를 활용하여 출력 변수인 y를 예측하는 방법</p>
</li>
<li><p>회귀분석 중 간단한 방법으로는 선형회귀분석(좌측 그림)이 있으며, 이를 바탕으로 더 복잡한 회귀분석(우측 그림)이 개발</p>
</li>
<li><p>대부분의 분류 모델(SVM, Decision Tree 등)로도 회귀가 가능함</p>
</li>
<li><p>단순 선형 회귀분석</p>
<blockquote>
<p>입력 변수가 x, 출력 변수가 y일 때, 단순 선형 회귀의 회귀식은 검은 선으로 나타낼 수 있음<br>어떻게 추정할까 ? 직선과 데이터의 차이가 평균적으로 가장 작아지는 직선</p>
</blockquote>
</li>
</ul>
<ol start="8">
<li>회귀계수추정</li>
</ol>
<ul>
<li><p>실제 값과 우리가 추정한 값의 차이가 적으면 적을 수록 좋은 것</p>
</li>
<li><p>실제 값과 우리가 추정한 값의 차이를 잔차라고 하며 이를 최소화 하는 방향으로 추정</p>
</li>
<li><p>잔차의 제곱합</p>
<blockquote>
<p>굳이 최소화 시키는 이유?<br>잔차의 합이 0이 되는 해는 무수히 많음(유일한 해를 찾지 못함)<br>잔차의 절대값의 합은 미분이 불가능한 형태<br>잔차의 제곱 합은 미분이 가능한 형태로 유일한 해를 찾을 수 있음</p>
</blockquote>
</li>
</ul>
<ol start="9">
<li>회귀계수의 의미</li>
</ol>
<ul>
<li><p>회귀 계수의 해석</p>
<blockquote>
<p>B1의 해석 : x1이 1단위 증가할때마다 y가 B1만큼 증가한다.</p>
</blockquote>
</li>
<li><p>선형 회귀의 정확도 평가</p>
<blockquote>
<p>선형 회귀는 잔차의 제곱합(SSE : Error sum of squares)을 최소화하는 방법으로 회귀 계수를 추정<br>즉 SSE가 작으면 작을수록 좋은 모델<br>MSE(Mean Squared Error)는 SSE를 표준화한 개념<br>회귀 분석은 결국 Y의 변동성을 얼마나 독립변수가 잘 설명하느냐가 중요<br>변수가 여러 개일 때 각각 Y를 설명하는 변동성이 크면 좋은 변수 &gt; p-value 자연스레 낮아짐<br>R = SSR / SST</p>
</blockquote>
</li>
</ul>
<ol start="10">
<li>회귀계수에 대한 검정</li>
</ol>
<ul>
<li>단순 선형 회귀분석의 검정<blockquote>
<p>표준오차<br>표본분포<br>귀무가설 : 채택하고 싶지 않은 가설, 기각 하기 너무 쉬운 가설. 변수가 추가 되면 추가 될수록 기각하기 쉬워진다.<br>대립가설 : 채택하고 싶은 가설<br>신뢰구간</p>
</blockquote>
</li>
</ul>
<ol start="11">
<li>다중 선형 회귀분석</li>
</ol>
<ul>
<li>회귀계수를 추정하는 것은 단순 선형 회귀분석과 동일하게 SSE를 최소화하는 방향으로 추정<blockquote>
<p>행렬<br>F-검정 : SSR / MSE(분자, 분모 모두 제곱합의 형태) : 제곱합의 형태로 검정을 하는 F 검정의 특성상 변수가 추가되면 자연스레 기각하기 쉬워진다. </p>
</blockquote>
</li>
</ul>
<ol start="12">
<li>다중공선성(Multi)</li>
</ol>
<ul>
<li><p>독립변수들이 강한 선형관계에 있을 때 다중공선성이 있다고 한다. </p>
</li>
<li><p>변수들 간의 다중공선성이 있다고 한다. 잘못된 변수 해석, 예측 정확도 하락 등을 야기시킨다.</p>
</li>
<li><p>다중공선성을 진단하는 방법</p>
<ul>
<li>VIF(Variance inflation factor), 변수들간의 Correlation 등으로 진단</li>
<li>다중공선성을 해결하는 방법</li>
</ul>
<ul>
<li>feature selection : 중요 변수만 선택하는 방법</li>
<li>변수를 줄이지 않고 활용하는 방법</li>
<li>상관행렬(correlation matrix) : 상관행렬 및 산점도를 보고 판단</li>
</ul>
</li>
<li><p>다중공선성을 근본적으로 해결하는 방법은 아직 없다.</p>
<blockquote>
<p>머신러닝 기법은 기본적으로 학습 데이터 내에서 예측력을 높이기 위해 최대한 많은 변수를 활용하려 함</p>
</blockquote>
</li>
</ul>
<ol start="13">
<li> 회귀모델의 성능 지표</li>
</ol>
<ul>
<li><p>R 스퀘어 : 변수가 증가하면 증가할수록 R스퀘어는 자연스레 증가</p>
</li>
<li><p>Adjusted R 스퀘어</p>
<blockquote>
<p>변수 수가 증가하면 자연스레 SSR이 증가하고 R2 또한 자연스레 증가함.<br>회귀분석의 성능지표로서 R2가 큰 의미가 없음<br>R2에 변수 수 만큼 penalty를 주는 지표</p>
</blockquote>
</li>
<li><p>AIC(Akaike information criterion)</p>
<blockquote>
<p>모델의 성능지표로서 MSE에 변수 수만큼 penalty를 주는 지표<br>일반적으로 회귀분석에서 Model Selection 할 때 많이 쓰이는 지표</p>
</blockquote>
</li>
<li><p>BIC(Bayes Information Criteria)</p>
<blockquote>
<p>AIC의 단점은 표본 n이 커질 때 부정확해짐<br>이를 보완한 지표가 BIC </p>
</blockquote>
</li>
</ul>
<ol start="14">
<li>모형의 성능 지표(주로 다루는 성능 지표)</li>
</ol>
<ul>
<li><p>MSE(Mean Squared Error)</p>
<blockquote>
<p>f가 제대로 추정 되었는지 평가하기 위해, 예측한 값이 실제 값과 유사한지 평가하는 척도가 필요함<br>MSE는 실제 종속 변수와 예측한 종속 변수 간의 차이<br>MSE가 작을수록 좋지만, MSE를 과도하게 줄이면 과적합의 오류를 범할 가능성이 있음</p>
</blockquote>
</li>
<li><p>MAPE</p>
<blockquote>
<p>f가 제대로 추정 되었는지 평가하기 위해, 예측한 값이 실제 값과 유사한지 평가하는 척도가 필요함<br>MAPE는 퍼센트 값을 가지며 0에 가까울수록 회귀 모형의 성능이 좋다고 해석할 수 있음<br>0~100% 사이의 값을 가져 이해하기 쉬우므로 성능 비교 해석이 가능</p>
</blockquote>
</li>
<li><p>정확도(Accuracy)</p>
<blockquote>
<p>정확도는 전체 데이터 중에서 모형으로 판단한 값이 실제 값과 부합하는 비율<br>분모는 전체 데이터가 되고 분자는 모형이 실제 정상을 정상으로 그리고 실제 이상을 이상으로 옳게 분류한 데이터<br>Accuracy = 옳게 분류된 데이터의 수 / 전체 데이터의 수</p>
</blockquote>
</li>
<li><p>정밀도, 재현율, 특이도</p>
<blockquote>
<p>분류 모형의 목적에 따라 다양한 지표를 볼 수 있음<br>정밀도(precision) = 옳게 분류된 불량 데이터의 수 / 불량으로 예측한 데이터 : 분류 모형이 불량으로 진단하기 위해 얼마나 잘 작동했는지<br>재현율(recall) = 옳게 분류된 불량 데이터의 수 / 실제 불량 데이터 : 불량 데이터 중 실제 불량이라고 진단한 제품의 비율(진단 확률)<br>특이도(specificity) = 옳게 분류된 정상 데이터의 수 / 실제 정상 데이터 : 분류 모형이 정상을 진단하기 위해 잘 작동하는지를 보여주는 지표</p>
</blockquote>
</li>
<li><p>G-mean, F1 measure</p>
<blockquote>
<p>실제 데이터의 대표적인 특성에는 불량(이상) 데이터를 탐지하는 것이 중요하다는 점과 이러한 불량 데이터는 매우 소수의 데이터라는 점<br>실제 데이터의 특성상 정확도 보다는 제1종 오류와 제 2종 오류 중 성능이 나쁜 쪽에 더 가중치를 주는 G-mean 지표나 불량에 관여하는 지표인 정밀도와 재현율만 고려하는 F1 measure가 더 고려해볼 수 있는 지표임</p>
</blockquote>
</li>
<li><p>ROC(Receiver Operating Characteristics) curve, AUC</p>
<blockquote>
<p>가로축을 1 - 특이도(specificity), 세로축을 재현율(recall)로 하여 시각화한 그래프를 ROC curve라고 함<br>이때 ROC curve의 면적을 AUC라고 함</p>
</blockquote>
</li>
</ul>
<h3 id="단순선형회귀분석-실습-단순선형회귀-적합-및-해석"><a href="#단순선형회귀분석-실습-단순선형회귀-적합-및-해석" class="headerlink" title="단순선형회귀분석 실습 - 단순선형회귀 적합 및 해석"></a>단순선형회귀분석 실습 - 단순선형회귀 적합 및 해석</h3><pre>
<code>
# target 제외한 데이터만 뽑기
boston_data = boston.drop(['Target'], axis=1)

# data 통계 뽑아보기
boston_data.describe()

'''
타겟 데이터
1978 보스턴 주택 가격
506개 타운의 주택 가격 중앙값 (단위 1,000 달러)

특징 데이터
CRIM: 범죄율
INDUS: 비소매상업지역 면적 비율
NOX: 일산화질소 농도
RM: 주택당 방 수
LSTAT: 인구 중 하위 계층 비율
B: 인구 중 흑인 비율
PTRATIO: 학생/교사 비율
ZN: 25,000 평방피트를 초과 거주지역 비율
CHAS: 찰스강의 경계에 위치한 경우는 1, 아니면 0
AGE: 1940년 이전에 건축된 주택의 비율
RAD: 방사형 고속도로까지의 거리
DIS: 직업센터의 거리
TAX: 재산세율
'''
</code>
</pre>

<ul>
<li>crim/rm/lstat 세게의 변수로 각각 단순 선형 회귀 분석하기</li>
</ul>
<pre>
<code>
## 변수 설정 target/crim/rm/lstat
target = boston[['Target']]
crim = boston[['CRIM']]
rm = boston[['RM']]
lstat = boston[['LSTAT']]
</code>
</pre>

<ul>
<li>target ~ crim 선형회귀분석</li>
</ul>
<pre>
<code>
# crim변수에 상수항추가하기
crim1 = sm.add_constant(crim, has_constant="add")
crim1

# sm.OLS 적합시키기
model1 = sm.OLS(target, crim1)
fitted_model1 = model1.fit()

# summary함수통해 결과출력
fitted_model1.summary()

## 회귀 계수 출력
fitted_model1.params
</code>
</pre>

<ul>
<li>y_hat=beta0 + beta1 * X 계산해보기</li>
</ul>
<pre>
<code>
#회귀 계수 x 데이터(X)
np.dot(crim1, fitted_model1.params)

## predict함수를 통해 yhat구하기
pred1 = fitted_model1.predict(crim1)

## 직접구한 yhat과 predict함수를 통해 구한 yhat차이
np.dot(crim1, fitted_model1.params) - pred1
</code>
</pre>

<ul>
<li>적합시킨 직선 시각화 </li>
</ul>
<pre>
<code>
## scatter plot
import matplotlib.pyplot as plt
plt.yticks(fontname = "Arial") #
plt.scatter(crim,target,label="data")
plt.plot(crim,pred1,label="result")
plt.legend()
plt.show()

plt.scatter(target,pred1)
plt.xlabel("real_value")
plt.ylabel("pred_value")
plt.show()

## residual 시각화
fitted_model1.resid.plot()
plt.xlabel("residual_number")
plt.show()

##잔차의 합계산해보기
np.sum(fitted_model1.resid)
</code>
</pre>

<ul>
<li>위와 동일하게 rm변수와 lstat 변수로 각각 단순선형회귀분석 적합시켜보기 </li>
</ul>
<pre>
<code>
# 상수항추가
rm1 = sm.add_constant(rm, has_constant="add")
lstat1 = sm.add_constant(lstat, has_constant="add")

# 회귀모델 적합
model2 = sm.OLS(target, rm1)
fitted_model2 = model2.fit()

model3 = sm.OLS(target, lstat1)
fitted_model3 = model3.fit()

# rm모델 결과 출력
fitted_model2.summary()

# lstat모델 결과 출력 
fitted_model3.summary()

## 각각 yhat_예측하기
pred2 = fitted_model2.predict(rm1)
pred3 = fitted_model3.predict(lstat1)
</code>
</pre>

<ul>
<li>식각화</li>
</ul>
<pre>
<code>
## rm모델 시각화
import matplotlib.pyplot as plt
plt.scatter(rm,target,label="data")
plt.plot(rm,pred2,label="result")
plt.legend()
plt.show()

## lstat모델 직선 시각화
import matplotlib.pyplot as plt
plt.scatter(lstat,target,label="data")
plt.plot(lstat,pred3,label="result")
plt.legend()
plt.show()

# rm모델 reisidual 시각화
fitted_model2.resid.plot()
plt.xlabel("residual_number")
plt.show()

# lstat모델 residual시각화
fitted_model3.resid.plot()
plt.xlabel("residual_number")
plt.show()

## 세모델의 residual비교
plt.figure(figsize=(12, 8))
fitted_model1.resid.plot(label="crim")
fitted_model2.resid.plot(label="rm")
fitted_model3.resid.plot(label="lstat")
plt.legend()
</code>
</pre>

<h3 id="다중선형회귀분석-실습1-다중회귀분석-적합-및-단순선형회귀와의-비교"><a href="#다중선형회귀분석-실습1-다중회귀분석-적합-및-단순선형회귀와의-비교" class="headerlink" title="다중선형회귀분석 실습1 - 다중회귀분석 적합 및 단순선형회귀와의 비교"></a>다중선형회귀분석 실습1 - 다중회귀분석 적합 및 단순선형회귀와의 비교</h3><ul>
<li>crim, rm, lstat 세개의 변수를 통해 다중회귀적합</li>
</ul>
<pre>
<code>
## bostan data에서 crim, rm, lstat 변수만 뽑아오기 
x_data = boston[['CRIM', 'RM', 'LSTAT']]
x_data.head()

#상수항 추기
x_data1 = sm.add_constant(x_data, has_constant='add')

# 회구모델 적합
multi_model = sm.OLS(target, x_data1)
fitted_multi_model = multi_model.fit()

# summary함수를 통해 결과출력
fitted_multi_model.summary()
</code>
</pre>

<ul>
<li>단순선형회귀모델의 회귀계수와 비교 </li>
</ul>
<pre>
<code>
## 단순선형회귀모델의 회귀 계수
print(fitted_model1.params)
print(fitted_model2.params)
print(fitted_model3.params)

## 다중선형회귀모델의 회귀 계수
print(fitted_multi_model.params)
</code>
</pre>

<ul>
<li>행렬연산을 통해 beta구하기 </li>
</ul>
<pre>
<code>
from numpy import linalg ##행렬연산을 통해 beta구하기 (X'X)-1X'y

ba = linalg.inv(np.dot(x_data1.T, x_data1))
np.dot(np.dot(ba, x_data1.T), target)

# y_hat구하기
pred4 = fitted_multi_model.predict(x_data1)
</code>
</pre>

<ul>
<li>residual plot</li>
</ul>
<pre>
<code>
fitted_multi_model.resid.plot()
plt.xlabel("residual_number")
plt.show()

fitted_model1.resid.plot(label="crim")
fitted_model2.resid.plot(label="rm")
fitted_model3.resid.plot(label="lstat")
fitted_multi_model.resid.plot(label="full")
plt.legend()
</code>
</pre>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/machine/" rel="tag"># machine</a>
              <a href="/tags/learning/" rel="tag"># learning</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/10/25/math-basic-1/" rel="prev" title="데이터 분석을 위한 기초 수학 1편">
      <i class="fa fa-chevron-left"></i> 데이터 분석을 위한 기초 수학 1편
    </a></div>
      <div class="post-nav-item">
    <a href="/2021/10/27/machine-learning-2/" rel="next" title="머신러닝  2편">
      머신러닝  2편 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    
  <div class="comments">
    <div id="disqus_thread">
      <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
    </div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#Part-01-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%EC%9D%98-%EA%B0%9C%EB%85%90%EA%B3%BC-%EC%A2%85%EB%A5%98"><span class="nav-number">1.</span> <span class="nav-text">Part.01 머신러닝의 개념과 종류</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Part-02-%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D"><span class="nav-number">2.</span> <span class="nav-text">Part. 02 회귀분석</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%EB%8B%A8%EC%88%9C%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D-%EC%8B%A4%EC%8A%B5-%EB%8B%A8%EC%88%9C%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80-%EC%A0%81%ED%95%A9-%EB%B0%8F-%ED%95%B4%EC%84%9D"><span class="nav-number">3.</span> <span class="nav-text">단순선형회귀분석 실습 - 단순선형회귀 적합 및 해석</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%EB%8B%A4%EC%A4%91%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D-%EC%8B%A4%EC%8A%B51-%EB%8B%A4%EC%A4%91%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D-%EC%A0%81%ED%95%A9-%EB%B0%8F-%EB%8B%A8%EC%88%9C%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80%EC%99%80%EC%9D%98-%EB%B9%84%EA%B5%90"><span class="nav-number">4.</span> <span class="nav-text">다중선형회귀분석 실습1 - 다중회귀분석 적합 및 단순선형회귀와의 비교</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">limjiin</p>
  <div class="site-description" itemprop="description">All stories about git, sql, python</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">28</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">41</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/limjiin" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;limjiin" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:limjiin0413@gmail.com" title="E-Mail → mailto:limjiin0413@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://blog.naver.com/lljin0413" title="Blog → https:&#x2F;&#x2F;blog.naver.com&#x2F;lljin0413" rel="noopener" target="_blank"><i class="fab fa-blog fa-fw"></i>Blog</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://instagram.com/ji_in_l" title="Instagram → https:&#x2F;&#x2F;instagram.com&#x2F;ji_in_l" rel="noopener" target="_blank"><i class="fab fa-instagram fa-fw"></i>Instagram</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">limjiin</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://jin.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>
<script>
  var disqus_config = function() {
    this.page.url = "https://limjiin.github.io/2021/10/25/machine-learning-1/";
    this.page.identifier = "2021/10/25/machine-learning-1/";
    this.page.title = "머신러닝  1편";
    };
  NexT.utils.loadComments(document.querySelector('#disqus_thread'), () => {
    if (window.DISQUS) {
      DISQUS.reset({
        reload: true,
        config: disqus_config
      });
    } else {
      var d = document, s = d.createElement('script');
      s.src = 'https://jin.disqus.com/embed.js';
      s.setAttribute('data-timestamp', '' + +new Date());
      (d.head || d.body).appendChild(s);
    }
  });
</script>

</body>
</html>
