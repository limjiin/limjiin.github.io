<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"limjiin.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="웹크롤링 기초를 배워보자!">
<meta property="og:type" content="article">
<meta property="og:title" content="python-crawler 1편">
<meta property="og:url" content="https://limjiin.github.io/2021/09/17/python-crawling/index.html">
<meta property="og:site_name" content="야무진의 기술 블로그">
<meta property="og:description" content="웹크롤링 기초를 배워보자!">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2021-09-17T11:19:36.078Z">
<meta property="article:modified_time" content="2021-10-11T04:51:20.015Z">
<meta property="article:author" content="limjiin">
<meta property="article:tag" content="python">
<meta property="article:tag" content="crawler">
<meta property="article:tag" content="BeautifulSoup">
<meta property="article:tag" content="selenium">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://limjiin.github.io/2021/09/17/python-crawling/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>python-crawler 1편 | 야무진의 기술 블로그</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">야무진의 기술 블로그</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">데이터 마케터 짜그리이지만, 계속 해보겠습니다.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://limjiin.github.io/2021/09/17/python-crawling/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="limjiin">
      <meta itemprop="description" content="All stories about git, sql, python">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="야무진의 기술 블로그">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          python-crawler 1편
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-09-17 20:19:36" itemprop="dateCreated datePublished" datetime="2021-09-17T20:19:36+09:00">2021-09-17</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-10-11 13:51:20" itemprop="dateModified" datetime="2021-10-11T13:51:20+09:00">2021-10-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python/" itemprop="url" rel="index"><span itemprop="name">python</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/2021/09/17/python-crawling/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2021/09/17/python-crawling/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>웹크롤링 기초를 배워보자!</p>
<span id="more"></span>

<h1 id="데이터-크롤링"><a href="#데이터-크롤링" class="headerlink" title="데이터 크롤링"></a><strong>데이터 크롤링</strong></h1><h2 id="크롤링이란"><a href="#크롤링이란" class="headerlink" title="크롤링이란?"></a><strong>크롤링이란?</strong></h2><blockquote>
<p>크롤러(crawler)는 자동화된 방법으로 웹을 탐색하는 컴퓨터 프로그램<br>‘웹 크롤링’(web crawling)??<br>‘데이터 크롤링’(data crawling)!!<br>구글링, 네이버 검색 등</p>
</blockquote>
<h2 id="웹-크롤링"><a href="#웹-크롤링" class="headerlink" title="웹 크롤링"></a><strong>웹 크롤링</strong></h2><blockquote>
<p>웹 서비스 내 정보를 수집하는 일<br>필요한 정보가 있다면?<br>API 확인 -&gt; 없으면 직접 크롤링<br>다만 서비스 제공자의 입장에서는??</p>
</blockquote>
<h3 id="웹-서핑을-하는-의식의-흐름"><a href="#웹-서핑을-하는-의식의-흐름" class="headerlink" title="웹 서핑을 하는 의식의 흐름"></a>웹 <strong>서핑</strong>을 하는 의식의 흐름</h3><blockquote>
<p>브라우저 오픈<br>원하는 인터넷페이지 주소 입력<br>화면이 열리면 찾고자 하는 정보를 스크롤 하면서 찾기<br>문자, 그림, 동영상 조회</p>
</blockquote>
<h3 id="웹-크롤링-하는-의식의-흐름"><a href="#웹-크롤링-하는-의식의-흐름" class="headerlink" title="웹 크롤링 하는 의식의 흐름"></a>웹 <strong>크롤링</strong> 하는 의식의 흐름</h3><blockquote>
<p>정보를 가져오고자 하는 url 정의<br>url 정보로 requests로 정보 요청<br>text 정보를 html로 변환<br>html에서 우리가 필요한 정보만 선별</p>
</blockquote>
<h3 id="웹-크롤링을-위해-BeautifulSoup-사용"><a href="#웹-크롤링을-위해-BeautifulSoup-사용" class="headerlink" title="웹 크롤링을 위해 BeautifulSoup 사용"></a>웹 크롤링을 위해 BeautifulSoup 사용</h3><blockquote>
<p>requests는 요청을 받기는 하지만 text로만 받음<br>API는 통신을 위해 정형화 된 데이터 형태의 text<br>우리가 원하는 데이터로 가공하기 위해 편의상 html로 변환<br>text를 html로 변환하는 모듈이 beautifulSoup</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/">https://www.crummy.com/software/BeautifulSoup/bs4/doc/</a></p>
<h3 id="간단한-데이터-크롤링으로-기본-개념잡기"><a href="#간단한-데이터-크롤링으로-기본-개념잡기" class="headerlink" title="간단한 데이터 크롤링으로 기본 개념잡기"></a>간단한 데이터 크롤링으로 기본 개념잡기</h3><pre>
<code>
# 필요패키지 import
import numpy as np
import pandas as pd
import requests # 크롤링에 사용하는 패키지
from bs4 import BeautifulSoup # html 변환에 사용함

# url정의
url = 'https://naver.com'

# requests로 url에 정보요청
response= requests.get(url)

# 정리되지 않은 정보
response.text

# 정보를 html 변환 (보기 쉽게)
html = BeautifulSoup(response.text, 'html.parser')

# html 내에서 우리가 보고 싶은 정보만 선별
html.select('img')

# 다음 뉴스 페이지 크롤링
url1 = 'https://www.daum.net/'

response = requests.get(url1)

html1 = BeautifulSoup(response.text, 'html.parser')

html1.select('img')
</code>
</pre>

<h3 id="실제-개발자가-작성한-코드로-확인된다"><a href="#실제-개발자가-작성한-코드로-확인된다" class="headerlink" title="실제 개발자가 작성한 코드로 확인된다"></a>실제 개발자가 작성한 코드로 확인된다</h3><blockquote>
<p>정제되지 않은 데이터로 가독성이 좋지 않음<br>우리는 이 중에서 우리가 원하는 정보를 선별해서 가져오는 작업을 진행합니다.<br>그러기에 html의 기본 구성을 살펴보도록 하겠습니다.</p>
</blockquote>
<h4 id="웹-페이지의-구성"><a href="#웹-페이지의-구성" class="headerlink" title="웹 페이지의 구성"></a>웹 페이지의 구성</h4><blockquote>
<p><strong>HTML(Hyper Text Markup Language)</strong><br>www 를 구성하는데 사용하는 국제표준 언어로서 컨텐츠와 레이아웃을 담고 있다</p>
</blockquote>
<blockquote>
<p><strong>&lt;태그&gt;</strong> 내용 <strong>&lt;/태그&gt;</strong><br>&lt;tag이름 class=”class이름1 class이름2” id=”주민번호” href=”주소”&gt;&lt;/tag이름&gt;</p>
</blockquote>
<blockquote>
<p>형태나 속성을 묘사하기 위한 구조적 언어 : HTML, CSS (계층이 있음)<br>웹의 작동 및 제어를 위한 프로그래밍 언어 :  Js</p>
</blockquote>
<h4 id="셀렉터"><a href="#셀렉터" class="headerlink" title="셀렉터"></a>셀렉터</h4><blockquote>
<p>용도 : html에서 내가 원하는 내용을 찾아내기 위해서<br>    <span class="news" id="1234">비비고 왕교자</span></p>
</blockquote>
<ul>
<li><p>단일 셀렉터</p>
<blockquote>
<p>html.select(‘span’) # 태그 이름이 span인 친구들 다 들고 옴<br>tag : span<br>class(별명, 그룹명) : .news</p>
</blockquote>
</li>
<li><p>클래스 포함 셀렉터</p>
<blockquote>
<p>html.select(‘span.news’)</p>
</blockquote>
</li>
<li><p>id 포함 셀렉터</p>
<blockquote>
<p>id(고유값) : #1234<br>html.select(‘span#1234’)</p>
</blockquote>
</li>
</ul>
<h4 id="복합-셀렉터"><a href="#복합-셀렉터" class="headerlink" title="복합 셀렉터"></a>복합 셀렉터</h4><pre><code>1. 조합 셀렉터
&lt;span&gt;1&lt;/span&gt;
&lt;span class=&quot;txt&quot;&gt;2&lt;/span&gt;
&lt;em class=&quot;txt&quot;&gt;3&lt;/em&gt;

태그 이름이 span이고 클래스 이름은 txt인 라인을 찾고 싶다. : span.txt
li 태그 중에서 id가 name 인 라인을 찾고\ 싶다. : li#name

2. 경로 셀렉터
&lt;ul&gt;
    &lt;li&gt;&lt;span&gt;이걸 찾으려면?&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;span&gt;이건 아님&lt;/span&gt;

ul 태그안 li 태그 안 span 라인을 찾는다
ul &gt; li &gt; span 혹은 ul li span
</code></pre>
<pre>
<code>
# 슬의생 드라마 크롤링
url2 = 'https://search.daum.net/search?w=tot&DA=YZR&t__nil_searchbox=btn&sug=&sugo=&sq=&o=&q=%EC%8A%AC%EC%9D%98%EC%83%9D'

response = requests.get(url2)

html2 = BeautifulSoup(response.text, 'html.parser')

html2.select('dd.cont')[0].text

for con in html2.select('dd.cont'):
    print(con.text)

# 슬의생 기사 크롤링
for title in html2.select('a.fn_tit_u')[1:]: #a.tit_main, fn_tit_n
    print('-'*20)
    print(title.text)

# 3개 이상의 드라마 크롤링
import time

dr_nm = ['도깨비', '호텔델루나', '슬기로운의사생활']

# name = input('제목을 입력해주세요 : ')

for name in dr_nm:
    # 순환은 빠르다
    print('-'*20)
    print(f'&#123;name&#125; 크롤링 중입니다.')
    url3 = f'https://search.daum.net/search?w=tot&DA=YZR&t__nil_searchbox=btn&sug=&sugo=&sq=&o=&q=&#123;name&#125;'

    # 초당 40~50회 요청
    # 다음에서 기계가 요청하는구나 막힘

    # 차단막는 코드
    seed = np.random.randint(100) # 시드도 난수로 만들고
    np.random.seed(seed) # 시드 생성
    a = np.random.randint(5) # 시드에서 난수 생성
    time.sleep(a)

    response = requests.get(url3)

    html3 = BeautifulSoup(response.text, 'html.parser')

    print(html3.select('dd.cont')[0].text)
print('크롤링 종료')
</code>
</pre>

<h2 id="다음에서-로또번호-가져오기"><a href="#다음에서-로또번호-가져오기" class="headerlink" title="다음에서 로또번호 가져오기"></a>다음에서 로또번호 가져오기</h2><ul>
<li>로또 번호 1개 가져오기</li>
</ul>
<pre>
<code>
# url 설정
url5 = 'https://search.daum.net/search?nil_suggest=btn&w=tot&DA=SBC&q=980%ED%9A%8C+%EB%8B%B9%EC%B2%A8+%EB%B2%88%ED%98%B8'

# requests로 데이터 요청하기
response = requests.get(url5)

# html로 변환
html5 = BeautifulSoup(response.text, 'html.parser')

html5.select('span.ball')

ball_num = []
for ball in html5.select('span.ball')[:-2]:
    ball = ball.text
    ball_num.append(ball)
ball_num
</code>
</pre>

<ul>
<li>전체 로또 번호 가져오기</li>
</ul>
<pre>
<code>
total_lotto = []

for i in range(680, 981):
    print('-'*20)
    print(f'&#123;i&#125;회차 당첨번호 크롤링 중입니다.')
    url5 = f'https://search.daum.net/search?nil_suggest=btn&w=tot&DA=SBC&q=&#123;i&#125;회
차+당첨+번호'

    # 차단막는 코드
    seed = np.random.randint(100) # 시드도 난수로 만들고
    np.random.seed(seed) # 시드 생성
    a = np.random.randint(5) # 시드에서 난수 생성
    time.sleep(a)

    # requests로 데이터 요청하기
    response = requests.get(url5)

    # html로 변환
    html5 = BeautifulSoup(response.text, 'html.parser')

    lotto = []
    for ball in html5.select('span.ball')[:-2]:
        lotto.append(ball.text)
    total_lotto.append(lotto)

print('크롤링이 종료되었습니다.')
</code>
</pre>

<ul>
<li>로또 번호 그래프 만들기</li>
</ul>
<pre>
<code>
lotto_array = np.array(total_lotto)

lotto_array.shape

# 1열로 만들어줌
lotto_array.reshape(-1, ).shape

# countplot으로 만들기
import seaborn as sns
import matplotlib.pyplot as plt
plt.figure(figsize=(15, 15))
sns.countplot(lotto_array.reshape(-1, ))

# 저장하기
df = pd.DataFrame(total_lotto)
df.to_csv('total_lotto.csv')
</code>
</pre>

<h3 id="웹-크롤링-에러-코드"><a href="#웹-크롤링-에러-코드" class="headerlink" title="웹 크롤링 에러 코드"></a>웹 크롤링 에러 코드</h3><ul>
<li>100 : 우리 이런정보 내주는거야</li>
<li>200 : 성공</li>
<li>300 : 우리 이 사이트 이리루 이사했어 일루가</li>
<li>400 : 유저가 요청을 잘못한경우</li>
<li>500 : 서버 문제</li>
</ul>
<pre>
<code>
requests.codes.ok
</code>
</pre>

<pre>
<code>
# 차단막는 코드
seed = np.random.randint(100)
np.random.seed(seed)
a = np.random.randint(5)
</code>
</pre>

<h2 id="네이버-키워드로-검색한-결과를-크롤링"><a href="#네이버-키워드로-검색한-결과를-크롤링" class="headerlink" title="네이버 키워드로 검색한 결과를 크롤링"></a><strong>네이버 키워드로 검색한 결과를 크롤링</strong></h2><pre>
<code>
key_word = input('키워드를 입력하세요 : ')
url = f'https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=1&ie=utf8&query=&#123;key_word&#125;'
response = requests.get(url)
html = BeautifulSoup(response.text, 'html.parser')
for name in html.select('a.api_txt_lines'):
    print(name.text, name.attrs['href'])

    temp_url = name.attrs['href']
</code>
</pre>

<h2 id="네이버-주식-시세-데이터-크롤링"><a href="#네이버-주식-시세-데이터-크롤링" class="headerlink" title="네이버 주식 시세 데이터 크롤링"></a>네이버 주식 시세 데이터 크롤링</h2><ul>
<li>동적페이지의 숨은 URL</li>
<li>동적 페이지에 요청을 할 때 정책에 필요한 정보를 같이 전달해줘야 함</li>
</ul>
<pre>
<code>
url = 'https://finance.naver.com/item/sise_day.naver?code=035720&page=1'

info = &#123;
    'referer' : 'https://finance.naver.com/item/sise_day.naver?code=035720&page=1',
    'user-agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.82 Safari/537.36'
&#125;

response = requests.get(url, headers=info)

html = BeautifulSoup(response.text, 'html.parser')

# 전체 데이터 tah
# 날짜 p10
html.select('span.p10') # p10 gray03

# 날짜 인덱스 살려서 활용하기
index = [date.text for date in html.select('span.p10')]

price = np.array([price.text.strip() for price in html.select('span.p11')]).reshape((-1, 6))

# 컬럼 정보에 해당하는 데이터 가져오기
columns= [col_name.text for col_name in html.select('th')]

df = pd.DataFrame(total_data,
                 index = index,
                  columns = columns)
df

def remove_str(x):
    return x.replace(',', '')

# 함수 적용
df['종가'] = df['종가'].apply(remove_str)
df

# 타임 변환
df['종가'] = df['종가'].astype(int)

# 그래프 만들기
df['종가'].sort_index().plot()
</code>
</pre>

<h4 id="네이버-주식-시세에서-가져온-정보를-np-array로-만들기"><a href="#네이버-주식-시세에서-가져온-정보를-np-array로-만들기" class="headerlink" title="네이버 주식 시세에서 가져온 정보를 np.array로 만들기"></a>네이버 주식 시세에서 가져온 정보를 np.array로 만들기</h4><pre>
<code>
# np.array로 만들기
total_data = np.array([item.text.strip() for item in html.select('span.tah')]).reshape((-1, 7))
total_data

# for 문으로 만들기
item_list = []
for item in html.select('span.tah'):
    item_list.append(item.text.strip())
item_array = np.array(item_list).reshape((-1, 7))
item_array
</code>
</pre>

<h2 id="총-20페이지-주가-정보-크롤링-해서-증가-그래프-출력"><a href="#총-20페이지-주가-정보-크롤링-해서-증가-그래프-출력" class="headerlink" title="총 20페이지 주가 정보 크롤링 해서 증가 그래프 출력"></a>총 20페이지 주가 정보 크롤링 해서 증가 그래프 출력</h2><pre>
<code>
info = &#123;
    'referer' : f'https://finance.naver.com/item/sise_day.naver?code=035720',
    'user-agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.82 Safari/537.36'
&#125;


index = []

total_data = np.array([])

for i in range(1, 21):
    
    seed = np.random.randint(100) # 시드도 난수로 만들고
    np.random.seed(seed) # 시드 생성
    a = np.random.randint(5) # 시드에서 난수 생성
    time.sleep(a)
    
    url = f'https://finance.naver.com/item/sise_day.naver?code=035720&page=&#123;i&#125;'
    
    # requests 요청 시 헤더 정보 추가
    response = requests.get(url, headers=info)
    
    # html 변환
    html = BeautifulSoup(response.text, 'html.parser')
    
    # 날짜 인덱스 살려서 활용하기
    for date in html.select('span.p10'):
        index.append(date.text)
    
    # 가격정보 추출
    price = np.array([price.text.strip() for price in html.select('span.p11')]).reshape((-1, 6))
    total_data = np.append(total_data, price).reshape((-1, 6))
    
    # 컬럼 정보에 해당하는 데이터 가져오기
    columns = [col_name.text for col_name in html.select('th')[1:]]
    
    print(f'&#123;i&#125;번째 크롤링 중입니다.')
    
# 데이터프레임 제작
df = pd.DataFrame(total_data,
             index = index,
             columns = columns

def remove_str(x):
    return x.replace(',', '')

df['종가'] = df['종가'].apply(remove_str)
df['종가'] = df['종가'].astype(int)
df['종가'].sort_index().plot()
</code>
</pre>

<h2 id="관심-있는-개별-종목의-시가총액-외국인-소진률-PER-PBR"><a href="#관심-있는-개별-종목의-시가총액-외국인-소진률-PER-PBR" class="headerlink" title="관심 있는 개별 종목의 시가총액, 외국인 소진률, PER, PBR"></a><strong>관심 있는 개별 종목의 시가총액, 외국인 소진률, PER, PBR</strong></h2><pre>
<code>
# url 정의
# 002020 = 코오롱
# 005930 = 삼성전자
# 035720 = 카카오
code = '035720'
url = f'https://finance.naver.com/item/main.naver?code=&#123;code&#125;'

# requests 요청
response = requests.get(url)

# html 변환
html = BeautifulSoup(response.text, 'html.parser')

# 데이터 선별
print('시가총액 : ', html.select('em#_market_sum')[0].text.strip())
print('외국인 소진률 : ', html.select('div.gray em')[2].text)
print('PER : ', html.select('em#_per')[0].text)
print('PBR : ', html.select('em#_pbr')[0].text)

import time

stock_list = ['005930', '002020', '323410']
total_data = []

for code in stock_list:
    time.sleep(np.random.randint(5))
    url = f'https://finance.naver.com/item/main.naver?code=&#123;code&#125;'
    print(f'&#123;code&#125; 크롤링 중입니다.')

    # requests 요청
    response = requests.get(url)

    # html 변환
    html = BeautifulSoup(response.text, 'html.parser')
    stock_data = []
    stock_data.append(html.select('em#_market_sum')[0].text.strip().replace('\n', '').replace('\t', ''))
    stock_data.append(html.select('div.gray em')[2].text)
    stock_data.append(html.select('em#_per')[0].text)
    stock_data.append(html.select('em#_pbr')[0].text)
    total_data.append(stock_data)

print(크롤링 종료)

total_data

df = pd.DataFrame(total_data,
                 index=['버킷스튜디오', 'SK하이닉스', '데브시스터즈'],
                 columns=['시가총액', '외국인소진률', 'PER', 'PBR'])
__
</code>
</pre>

<h2 id="네이버-데이터랩-인기검색어-크롤링"><a href="#네이버-데이터랩-인기검색어-크롤링" class="headerlink" title="네이버 데이터랩 인기검색어 크롤링"></a>네이버 데이터랩 인기검색어 크롤링</h2><pre>
<code>
url = 'https://datalab.naver.com/shoppingInsight/getKeywordRank.naver'

info = &#123;
    'referer' : 'https://datalab.naver.com/',
    'user-agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.82 Safari/537.36'
&#125;

response = requests.post(url, headers=info)

import json

data = json.loads(response.text)

data[0]

for item in data[0]['ranks']:
    print(item['keyword'])
</code>
</pre>

<h2 id="다음-주식-일자별-주가-데이터-크롤링"><a href="#다음-주식-일자별-주가-데이터-크롤링" class="headerlink" title="다음 주식 일자별 주가 데이터 크롤링"></a>다음 주식 일자별 주가 데이터 크롤링</h2><pre>
<code>
url = 'https://finance.daum.net/api/quote/A002020/days?symbolCode=A002020&page=1&perPage=10&pagination=true'

info = &#123;
    'referer' : 'https://finance.daum.net/quotes/A002020',
    'user-agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.82 Safari/537.36'
&#125;

response = requests.get(url, headers=info)

response.text

data = json.loads(response.text)

# json 파싱 함수
from pandas.io.json import json_normalize

df = pd.DataFrame(data['data'])
df
</code>
</pre>

<h2 id="파파고-API"><a href="#파파고-API" class="headerlink" title="파파고 API"></a>파파고 API</h2><pre>
<code>
url = "https://openapi.naver.com/v1/papago/n2mt"

info = &#123;
    "Content-Type" : "application/x-www-form-urlencoded; charset=UTF-8",
    "X-Naver-Client-Id" : "jqRNFpaeC_H1CK1avZRq",
    "X-Naver-Client-Secret" : "WPIGbWh757"
&#125;

data = &#123;
    'source' : 'ko',
    'target' : 'en',
    'text' : '만나서 반갑습니다.'
&#125;

response = requests.post(url,headers=info, data=data)
response.text

result = json.loads(response.text)
result

result['message']['result']['translatedText']
</code>
</pre>

<h4 id="자동으로-한국어를-영어로-출력하기"><a href="#자동으로-한국어를-영어로-출력하기" class="headerlink" title="자동으로 한국어를 영어로 출력하기"></a>자동으로 한국어를 영어로 출력하기</h4><pre>
<code>
def papago():

    x = str(input('번역이 필요한 한국어를 입력하세요 : '))
    # url 설정
    url = "https://openapi.naver.com/v1/papago/n2mt"

    info = &#123;
        "Content-Type" : "application/x-www-form-urlencoded; charset=UTF-8",
        "X-Naver-Client-Id" : "jqRNFpaeC_H1CK1avZRq",
        "X-Naver-Client-Secret" : "WPIGbWh757"
    &#125;

    data = &#123;
        'source':'ko',
        'target':'en',
        'text': x
    &#125;

    response = requests.post(url, headers=info, data=data)
    result = json.loads(response.text)
    print(result['message']['result']['translatedText'])
</code>
</pre>

<p><a target="_blank" rel="noopener" href="https://developers.naver.com/main/">https://developers.naver.com/main/</a></p>
<h2 id="공공데이터"><a href="#공공데이터" class="headerlink" title="공공데이터"></a>공공데이터</h2><pre>
<code>
url = 'http://smarttour.junggu.seoul.kr//junggu/openapi/culture.do'

response = requests.get(url)

data = json.loads(response.text)

for i in range(i):
    print(data['spot_Data'][i]['spot_Address'][1])
</code>
</pre>

<p><a target="_blank" rel="noopener" href="https://www.data.go.kr/index.do">https://www.data.go.kr/index.do</a></p>
<h2 id="selenium-셀레니움"><a href="#selenium-셀레니움" class="headerlink" title="selenium(셀레니움)"></a>selenium(셀레니움)</h2><blockquote>
<p>웹 어플리케이션 테스트를 위한 프레임워크.<br>다양한 브라우저 작동을 지원하며 크롤링에도 활용가능.<br>정적, 동적페이지 크롤링으로도 접근이 불가능한 데이터에 접근할 때 유용하게 사용<br>현존하는 거의 모든 웹브라우저를 다양한 언어를 통해 제어 가능</p>
</blockquote>
<h2 id="selenium-Setting"><a href="#selenium-Setting" class="headerlink" title="selenium Setting"></a>selenium Setting</h2><blockquote>
<p>사용해야 하는 브라우저의 웹드라이버 다운 필요<br>크롬 환경설정 -&gt; 크롬 정보로 크롬 버전 확인 필요<br>셀레니움은 이 웹 드라이버 API를 제어하는 파이썬 패키지입니다.</p>
</blockquote>
<ul>
<li>크롬 드라이버 다운로드<br><a target="_blank" rel="noopener" href="https://chromedriver.chromium.org/downloads">https://chromedriver.chromium.org/downloads</a></li>
</ul>
<pre>
<code>
# 셀레니움 설치
!pip install selenium

# 셀레니움 import
from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from bs4 import BeautifulSoup
</code>
</pre>

<h2 id="간단한-브라우저-컨트롤로-기본-개념잡기"><a href="#간단한-브라우저-컨트롤로-기본-개념잡기" class="headerlink" title="간단한 브라우저 컨트롤로 기본 개념잡기"></a>간단한 브라우저 컨트롤로 기본 개념잡기</h2><pre>
<code>
# 크롬창 열기
driver = webdriver.Chrome('./chromedriver.exe')

# 윈도우 사용자분들
# driver = webdriver.Chrome('.//chromedriver.exe')

# 설정한 url로 데이터 get함수로 요청
url = 'https://naver.com'
driver.get(url)

# 키워드를 입력받아 검색창의 xpath에 send_keys 함수로 키워드 입력
key_word = input('키워드를 입력하세요 : ') + '\n'
# 녹색창에 입력값 지우기는 clear
# 입력은 send_keys
driver.find_element_by_xpath('//*[@id="query"]').clear()
driver.find_element_by_xpath('//*[@id="query"]').send_keys(key_word)

# 검색결과의 news 탭 클릭
driver.find_element_by_xpath('//*[@id="lnb"]/div[1]/div/ul/li[7]/a').click()
_*
</code>
</pre>

<h2 id="네이버-로그인-시도-실습"><a href="#네이버-로그인-시도-실습" class="headerlink" title="네이버 로그인 시도 실습"></a>네이버 로그인 시도 실습</h2><pre>
<code>
# 네이버 메인에서 로그인 페이지로 이동
driver.find_element_by_xpath('//*[@id="account"]/a').click()

# 로그인 정보 입력
naver_id = input('아이디를 입력하세요 : ')
naver_pw = input('비밀번호를 입력하세요 : ') + '\n'
driver.find_element_by_xpath('//*[@id="id"]').send_keys(naver_id)
driver.find_element_by_xpath('//*[@id="pw"]').send_keys(naver_pw)
_*

# 자동 입력 방지 때문에 사용하기 어려움
</code>
</pre>

<h2 id="인스타그램-크롤링"><a href="#인스타그램-크롤링" class="headerlink" title="인스타그램 크롤링"></a>인스타그램 크롤링</h2><pre>
<code>
# 컨트롤 할 크롬 브라우저 생성
driver = webdriver.Chrome('./chromedriver.exe')

# url 페이지 이동
url = 'https://www.instagram.com/'
driver.get(url)

# 페이스북 로그인 클릭
driver.find_element_by_xpath('//*[@id="loginForm"]/div/div[5]/button/span[2]').click()

# 페이스북 로그인 정보 입력 후 로그인 버튼 클릭
ins_id = '1234'
ins_pw = 'a1234'
# 페이지 로딩에 약간의 시간이 필요하면
driver.find_element_by_xpath('//*[@id="email"]').send_keys(ins_id)
driver.find_element_by_xpath('//*[@id="pass"]').send_keys(ins_pw)
time.sleep(3)
driver.find_element_by_xpath('//*[@id="loginbutton"]').click()

# 2단계 인증
driver.find_element_by_xpath('//*[@id="approvals_code"]').send_keys('인증코드')
driver.find_element_by_xpath('//*[@id="checkpointSubmitButton"]').click()

# 알림설정 팝업창 나중에 하기 클릭
driver.find_element_by_xpath('').click()

# 검색 키워드로 크롤링을 하기 위해 검색어 입력
driver.find_element_by_xpath('//*[@id="react-root"]/section/nav/div[2]/div/div/div[2]/input').send_keys('해방촌\n')

# 첫번째 항목 접근
driver.find_element_by_xpath('//*[@id="react-root"]/section/nav/div[2]/div/div/div[2]/div[3]/div/div[2]/div/div[1]/a/div').click()

# 첫번째 포스팅 클릭
driver.find_element_by_xpath('//*[@id="react-root"]/section/main/article/div[1]/div/div/div[1]/div[1]/a/div[1]').click()

# 좋아요 누르기
driver.find_element_by_xpath('/html/body/div[6]/div[2]/div/article/div/div[3]/div/div/section[1]/span[1]/button').click()

# 댓글 달기
driver.find_element_by_xpath('/html/body/div[6]/div[2]/div/article/div/div[3]/div/div/section[1]/span[2]/button').click()

# 댓글 영역에 댓글 쓰기
driver.find_element_by_xpath('/html/body/div[6]/div[2]/div/article/div/div[3]/div/div/section[3]/div/form/textarea').send_keys('맛있어보여요~')

# 팔로우
driver.find_element_by_xpath('/html/body/div[6]/div[2]/div/article/div/div[2]/div/div[1]/div/header/div[2]/div[1]/div[2]/button').click()

# 포스팅 image url 따오기
# 기존의 html 설렉터를 만들어서 전달하고
# css_selector 사용
# driver 객체 형태로 받아옴
image = driver.find_element_by_css_selector('img.FFVAD')

# image 변수에서 src 속성에 접근
image_url = image.get_attribute('src')
# html['attris']

# 이미지 저장을 위한 패키지
import urllib
# 이미지 저장
urllib.request.urlretrieve(image_url, './test_image.jpg')

# 앞 포스팅으로 이동하는 꺽쇠 버튼(첫 포스팅은 작동을 뒤로합니다.)

# 뒤 포스팅으로 이동하는 꺾쇠 버튼
# driver.find_element_by_xpath('/html/body/div[6]/div[2]/div/article/div/div[2]/div/div[1]/div[2]/div/button[1]').click()

# 2번째 포스팅부터 뒤로 이동하는 꺽쇠 버튼
# driver.find_element_by_xpath('/html/body/div[6]/div[2]/div/article/div/div[2]/div/div[1]/div[2]/div/button[2]').click()

# 맨 마지막 포스팅부터 앞으로 이동하는 꺽쇠 버튼
driver.find_element_by_xpath('/html/body/div[6]/div[2]/div/article/div/div[2]/div/div[1]/div[2]/div/button').click()

# 첫 게시물 넘기는 꺽쇠 버튼
driver.find_element_by_xpath('/html/body/div[6]/div[1]/div/div/a').click()

# 해시태그 추출하기
html = BeautifulSoup(driver.page_source, 'html.parser')

html.select('a.xil3i')

for tag in html.select('a.xil3i'):
    print(tag.text[1:])

*******
</code>
</pre>

<h2 id="인스타그램-셀레니움-크롤링-코드-합치기"><a href="#인스타그램-셀레니움-크롤링-코드-합치기" class="headerlink" title="인스타그램 셀레니움 크롤링 코드 합치기"></a>인스타그램 셀레니움 크롤링 코드 합치기</h2><pre>
<code>
from selenium import webdriver
from selenium.webdriver.common.keys import Keys 
from bs4 import BeautifulSoup
import pandas as pd
import numpy as np

driver = webdriver.Chrome('./chromedriver.exe')

url = 'https://www.instagram.com/'
driver.get(url)

# 페이스북으로 로그인
driver.find_element_by_xpath('//*[@id="loginForm"]/div/div[5]/button').click()

driver.find_element_by_xpath('//*[@id="email"]').send_keys('1234')
driver.find_element_by_xpath('//*[@id="pass"]').send_keys('a1234\n')

# 알림 나중에 설정
driver.find_element_by_xpath('/html/body/div[5]/div/div/div/div[3]/button[2]').click()

# 키워드로 검색
driver.find_element_by_xpath('//*[@id="react-root"]/section/nav/div[2]/div/div/div[2]/input').send_keys('연남카페\n')
driver.find_element_by_xpath('//*[@id="react-root"]/section/nav/div[2]/div/div/div[2]/div[3]/div/div[2]/div/div[1]/a/div/div[2]').click()

# 첫번째 게시글 클릭
driver.find_element_by_xpath('//*[@id="react-root"]/section/main/article/div[1]/div/div/div[1]/div[1]').click()

# 해당 키워드로 검색한 포스팅의 작성일자, 좋아요 수, tag 크롤링 하기
for i in range(5):

    print(f'&#123;i&#125;번째 크롤링 중입니다.')

    html = BeautifulSoup(driver.page_source, 'html.parser')

    time.sleep(1)

    for like in html.select('a.zV_Nj span'):
        print(f'좋아요 수 : &#123;like.text&#125;')

    for date_ins in html.select('a.c-Yi7'):
        print(f'작성일자 : &#123;date_ins.text&#125;')

    for tag in html.select('a.xil3i'):
        print(f'태그 : &#123;tag.text[1:]&#125;')

    if i == 0:
        driver.find_element_by_xpath('/html/body/div[6]/div[1]/div/div/a').click()

    else:
        driver.find_element_by_xpath('/html/body/div[6]/div[1]/div/div/a[2]').click()
</code>
</pre>

<h4 id="인스타그램-크롤링-데이터프레임에-넣기"><a href="#인스타그램-크롤링-데이터프레임에-넣기" class="headerlink" title="인스타그램 크롤링  데이터프레임에 넣기"></a>인스타그램 크롤링  데이터프레임에 넣기</h4><pre>
<code>
url = 'https://www.instagram.com/'
driver.get(url)

# 페이스북으로 로그인
driver.find_element_by_xpath('//*[@id="loginForm"]/div/div[5]/button').click()

driver.implicitly_wait(10) #페이지가 뜰 때까지 최대 10초 동안 기다리겠다

# 키워드로 검색
driver.find_element_by_xpath('//*[@id="react-root"]/section/nav/div[2]/div/div/div[2]/input').send_keys('해방촌\n')

time.sleep(3)

driver.find_element_by_xpath('//*[@id="react-root"]/section/nav/div[2]/div/div/div[2]/div[3]/div/div[2]/div/div[1]/a/div/div[2]').click()

time.sleep(3)

# 첫번째 게시글 클릭
driver.find_element_by_xpath('//*[@id="react-root"]/section/main/article/div[1]/div/div/div[1]/div[1]').click()

page = 50
dates = []
likes = []
tags = []

for i in range(50):

    print(f'&#123;i&#125;번째 크롤링 중입니다.')

    html = BeautifulSoup(driver.page_source, 'html.parser')

    time.sleep(2)

    if i == 0:
        date = html.select('time._1o9PC')[0]['title'] # 게시일
        like = html.select('a.zV_Nj span')[0].text # 좋아요 갯수
        tags = [tag.text[1:] for tag in html.select('a.xil3i')] # 태그

        print(date, like, tags)

        driver.find_element_by_xpath('/html/body/div[6]/div[1]/div/div/a').click()

    elif i >= 9:

    else:
        driver.find_element_by_xpath('/html/body/div[6]/div[1]/div/div/a[2]').click()
        time.sleep(10)

        html = BeautifulSoup(driver.page_source, 'html.parser')
        date = html.select('time._1o9PC')[0]['title']
        like = html.select('a.zV_Nj span')[0].text # 빈게 들어옴

        if like == []:
            like = html.select('span.vcOH2 span')[0].text
        tags = [tag.text[1:] for tag in html.select('a.xil3i')]

        print(date, like, tags)

    print('-'*20)

df = pd.DataFrame(total_like,
                  index=total_date)
df
</code>
</pre>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/python/" rel="tag"># python</a>
              <a href="/tags/crawler/" rel="tag"># crawler</a>
              <a href="/tags/BeautifulSoup/" rel="tag"># BeautifulSoup</a>
              <a href="/tags/selenium/" rel="tag"># selenium</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/09/16/python-image-visualization/" rel="prev" title="python-image-visualization">
      <i class="fa fa-chevron-left"></i> python-image-visualization
    </a></div>
      <div class="post-nav-item">
    <a href="/2021/09/27/python-crawling-2/" rel="next" title="python-crawler 2편">
      python-crawler 2편 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    
  <div class="comments">
    <div id="disqus_thread">
      <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
    </div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%81%AC%EB%A1%A4%EB%A7%81"><span class="nav-number">1.</span> <span class="nav-text">데이터 크롤링</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%ED%81%AC%EB%A1%A4%EB%A7%81%EC%9D%B4%EB%9E%80"><span class="nav-number">1.1.</span> <span class="nav-text">크롤링이란?</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%EC%9B%B9-%ED%81%AC%EB%A1%A4%EB%A7%81"><span class="nav-number">1.2.</span> <span class="nav-text">웹 크롤링</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%EC%9B%B9-%EC%84%9C%ED%95%91%EC%9D%84-%ED%95%98%EB%8A%94-%EC%9D%98%EC%8B%9D%EC%9D%98-%ED%9D%90%EB%A6%84"><span class="nav-number">1.2.1.</span> <span class="nav-text">웹 서핑을 하는 의식의 흐름</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%EC%9B%B9-%ED%81%AC%EB%A1%A4%EB%A7%81-%ED%95%98%EB%8A%94-%EC%9D%98%EC%8B%9D%EC%9D%98-%ED%9D%90%EB%A6%84"><span class="nav-number">1.2.2.</span> <span class="nav-text">웹 크롤링 하는 의식의 흐름</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%EC%9B%B9-%ED%81%AC%EB%A1%A4%EB%A7%81%EC%9D%84-%EC%9C%84%ED%95%B4-BeautifulSoup-%EC%82%AC%EC%9A%A9"><span class="nav-number">1.2.3.</span> <span class="nav-text">웹 크롤링을 위해 BeautifulSoup 사용</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%EA%B0%84%EB%8B%A8%ED%95%9C-%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%81%AC%EB%A1%A4%EB%A7%81%EC%9C%BC%EB%A1%9C-%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90%EC%9E%A1%EA%B8%B0"><span class="nav-number">1.2.4.</span> <span class="nav-text">간단한 데이터 크롤링으로 기본 개념잡기</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%EC%8B%A4%EC%A0%9C-%EA%B0%9C%EB%B0%9C%EC%9E%90%EA%B0%80-%EC%9E%91%EC%84%B1%ED%95%9C-%EC%BD%94%EB%93%9C%EB%A1%9C-%ED%99%95%EC%9D%B8%EB%90%9C%EB%8B%A4"><span class="nav-number">1.2.5.</span> <span class="nav-text">실제 개발자가 작성한 코드로 확인된다</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%EC%9B%B9-%ED%8E%98%EC%9D%B4%EC%A7%80%EC%9D%98-%EA%B5%AC%EC%84%B1"><span class="nav-number">1.2.5.1.</span> <span class="nav-text">웹 페이지의 구성</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EC%85%80%EB%A0%89%ED%84%B0"><span class="nav-number">1.2.5.2.</span> <span class="nav-text">셀렉터</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EB%B3%B5%ED%95%A9-%EC%85%80%EB%A0%89%ED%84%B0"><span class="nav-number">1.2.5.3.</span> <span class="nav-text">복합 셀렉터</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%EB%8B%A4%EC%9D%8C%EC%97%90%EC%84%9C-%EB%A1%9C%EB%98%90%EB%B2%88%ED%98%B8-%EA%B0%80%EC%A0%B8%EC%98%A4%EA%B8%B0"><span class="nav-number">1.3.</span> <span class="nav-text">다음에서 로또번호 가져오기</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%EC%9B%B9-%ED%81%AC%EB%A1%A4%EB%A7%81-%EC%97%90%EB%9F%AC-%EC%BD%94%EB%93%9C"><span class="nav-number">1.3.1.</span> <span class="nav-text">웹 크롤링 에러 코드</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%EB%84%A4%EC%9D%B4%EB%B2%84-%ED%82%A4%EC%9B%8C%EB%93%9C%EB%A1%9C-%EA%B2%80%EC%83%89%ED%95%9C-%EA%B2%B0%EA%B3%BC%EB%A5%BC-%ED%81%AC%EB%A1%A4%EB%A7%81"><span class="nav-number">1.4.</span> <span class="nav-text">네이버 키워드로 검색한 결과를 크롤링</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%EB%84%A4%EC%9D%B4%EB%B2%84-%EC%A3%BC%EC%8B%9D-%EC%8B%9C%EC%84%B8-%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%81%AC%EB%A1%A4%EB%A7%81"><span class="nav-number">1.5.</span> <span class="nav-text">네이버 주식 시세 데이터 크롤링</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%EB%84%A4%EC%9D%B4%EB%B2%84-%EC%A3%BC%EC%8B%9D-%EC%8B%9C%EC%84%B8%EC%97%90%EC%84%9C-%EA%B0%80%EC%A0%B8%EC%98%A8-%EC%A0%95%EB%B3%B4%EB%A5%BC-np-array%EB%A1%9C-%EB%A7%8C%EB%93%A4%EA%B8%B0"><span class="nav-number">1.5.0.1.</span> <span class="nav-text">네이버 주식 시세에서 가져온 정보를 np.array로 만들기</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%EC%B4%9D-20%ED%8E%98%EC%9D%B4%EC%A7%80-%EC%A3%BC%EA%B0%80-%EC%A0%95%EB%B3%B4-%ED%81%AC%EB%A1%A4%EB%A7%81-%ED%95%B4%EC%84%9C-%EC%A6%9D%EA%B0%80-%EA%B7%B8%EB%9E%98%ED%94%84-%EC%B6%9C%EB%A0%A5"><span class="nav-number">1.6.</span> <span class="nav-text">총 20페이지 주가 정보 크롤링 해서 증가 그래프 출력</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%EA%B4%80%EC%8B%AC-%EC%9E%88%EB%8A%94-%EA%B0%9C%EB%B3%84-%EC%A2%85%EB%AA%A9%EC%9D%98-%EC%8B%9C%EA%B0%80%EC%B4%9D%EC%95%A1-%EC%99%B8%EA%B5%AD%EC%9D%B8-%EC%86%8C%EC%A7%84%EB%A5%A0-PER-PBR"><span class="nav-number">1.7.</span> <span class="nav-text">관심 있는 개별 종목의 시가총액, 외국인 소진률, PER, PBR</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%EB%84%A4%EC%9D%B4%EB%B2%84-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%9E%A9-%EC%9D%B8%EA%B8%B0%EA%B2%80%EC%83%89%EC%96%B4-%ED%81%AC%EB%A1%A4%EB%A7%81"><span class="nav-number">1.8.</span> <span class="nav-text">네이버 데이터랩 인기검색어 크롤링</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%EB%8B%A4%EC%9D%8C-%EC%A3%BC%EC%8B%9D-%EC%9D%BC%EC%9E%90%EB%B3%84-%EC%A3%BC%EA%B0%80-%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%81%AC%EB%A1%A4%EB%A7%81"><span class="nav-number">1.9.</span> <span class="nav-text">다음 주식 일자별 주가 데이터 크롤링</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%ED%8C%8C%ED%8C%8C%EA%B3%A0-API"><span class="nav-number">1.10.</span> <span class="nav-text">파파고 API</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%EC%9E%90%EB%8F%99%EC%9C%BC%EB%A1%9C-%ED%95%9C%EA%B5%AD%EC%96%B4%EB%A5%BC-%EC%98%81%EC%96%B4%EB%A1%9C-%EC%B6%9C%EB%A0%A5%ED%95%98%EA%B8%B0"><span class="nav-number">1.10.0.1.</span> <span class="nav-text">자동으로 한국어를 영어로 출력하기</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%EA%B3%B5%EA%B3%B5%EB%8D%B0%EC%9D%B4%ED%84%B0"><span class="nav-number">1.11.</span> <span class="nav-text">공공데이터</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#selenium-%EC%85%80%EB%A0%88%EB%8B%88%EC%9B%80"><span class="nav-number">1.12.</span> <span class="nav-text">selenium(셀레니움)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#selenium-Setting"><span class="nav-number">1.13.</span> <span class="nav-text">selenium Setting</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%EA%B0%84%EB%8B%A8%ED%95%9C-%EB%B8%8C%EB%9D%BC%EC%9A%B0%EC%A0%80-%EC%BB%A8%ED%8A%B8%EB%A1%A4%EB%A1%9C-%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90%EC%9E%A1%EA%B8%B0"><span class="nav-number">1.14.</span> <span class="nav-text">간단한 브라우저 컨트롤로 기본 개념잡기</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%EB%84%A4%EC%9D%B4%EB%B2%84-%EB%A1%9C%EA%B7%B8%EC%9D%B8-%EC%8B%9C%EB%8F%84-%EC%8B%A4%EC%8A%B5"><span class="nav-number">1.15.</span> <span class="nav-text">네이버 로그인 시도 실습</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%EC%9D%B8%EC%8A%A4%ED%83%80%EA%B7%B8%EB%9E%A8-%ED%81%AC%EB%A1%A4%EB%A7%81"><span class="nav-number">1.16.</span> <span class="nav-text">인스타그램 크롤링</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%EC%9D%B8%EC%8A%A4%ED%83%80%EA%B7%B8%EB%9E%A8-%EC%85%80%EB%A0%88%EB%8B%88%EC%9B%80-%ED%81%AC%EB%A1%A4%EB%A7%81-%EC%BD%94%EB%93%9C-%ED%95%A9%EC%B9%98%EA%B8%B0"><span class="nav-number">1.17.</span> <span class="nav-text">인스타그램 셀레니움 크롤링 코드 합치기</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%EC%9D%B8%EC%8A%A4%ED%83%80%EA%B7%B8%EB%9E%A8-%ED%81%AC%EB%A1%A4%EB%A7%81-%EB%8D%B0%EC%9D%B4%ED%84%B0%ED%94%84%EB%A0%88%EC%9E%84%EC%97%90-%EB%84%A3%EA%B8%B0"><span class="nav-number">1.17.0.1.</span> <span class="nav-text">인스타그램 크롤링  데이터프레임에 넣기</span></a></li></ol></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">limjiin</p>
  <div class="site-description" itemprop="description">All stories about git, sql, python</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">28</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">41</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/limjiin" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;limjiin" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:limjiin0413@gmail.com" title="E-Mail → mailto:limjiin0413@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://blog.naver.com/lljin0413" title="Blog → https:&#x2F;&#x2F;blog.naver.com&#x2F;lljin0413" rel="noopener" target="_blank"><i class="fab fa-blog fa-fw"></i>Blog</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://instagram.com/ji_in_l" title="Instagram → https:&#x2F;&#x2F;instagram.com&#x2F;ji_in_l" rel="noopener" target="_blank"><i class="fab fa-instagram fa-fw"></i>Instagram</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">limjiin</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://jin.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>
<script>
  var disqus_config = function() {
    this.page.url = "https://limjiin.github.io/2021/09/17/python-crawling/";
    this.page.identifier = "2021/09/17/python-crawling/";
    this.page.title = "python-crawler 1편";
    };
  NexT.utils.loadComments(document.querySelector('#disqus_thread'), () => {
    if (window.DISQUS) {
      DISQUS.reset({
        reload: true,
        config: disqus_config
      });
    } else {
      var d = document, s = d.createElement('script');
      s.src = 'https://jin.disqus.com/embed.js';
      s.setAttribute('data-timestamp', '' + +new Date());
      (d.head || d.body).appendChild(s);
    }
  });
</script>

</body>
</html>
